{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8bc27e",
   "metadata": {},
   "source": [
    "Supervised Learning â€“ Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a54dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "Dataset shape: (64374, 12)\n",
      "Columns: ['CustomerID', 'Age', 'Gender', 'Tenure', 'Usage Frequency', 'Support Calls', 'Payment Delay', 'Subscription Type', 'Contract Length', 'Total Spend', 'Last Interaction', 'Churn']\n",
      "\n",
      "ðŸŽ¯ Target variable selected: Churn\n",
      "\n",
      "âœ… Data cleaned successfully!\n",
      "Final shape after cleaning: (64374, 13)\n",
      "\n",
      "ðŸ“¦ Training set size: (51499, 13)\n",
      "ðŸ“¦ Testing set size: (12875, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAMI ULLAH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "ðŸ“Š MODEL ACCURACY COMPARISON\n",
      "=============================\n",
      "Logistic Regression Accuracy : 0.8375\n",
      "Random Forest Accuracy       : 0.9964\n",
      "\n",
      "Detailed Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6793\n",
      "           1       1.00      0.99      1.00      6082\n",
      "\n",
      "    accuracy                           1.00     12875\n",
      "   macro avg       1.00      1.00      1.00     12875\n",
      "weighted avg       1.00      1.00      1.00     12875\n",
      "\n",
      "\n",
      "âœ… Random Forest performs better than Logistic Regression.\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# ðŸ“Š CUSTOMER CHURN PREDICTION - CLASSIFICATION\n",
    "# Logistic Regression vs Random Forest\n",
    "# =============================================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ==========================\n",
    "# ðŸ§¾ 1. LOAD DATA\n",
    "# ==========================\n",
    "df = pd.read_csv(\"customer_churn_dataset.csv\")\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# ==========================\n",
    "# ðŸŽ¯ 2. DEFINE TARGET VARIABLE\n",
    "# ==========================\n",
    "# If 'Churn' column exists, use it; otherwise look for similar ones\n",
    "target_candidates = [\"Churn\", \"Exited\", \"Customer Status\", \"Attrition_Flag\"]\n",
    "target_col = None\n",
    "\n",
    "for col in target_candidates:\n",
    "    if col in df.columns:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\"âŒ Target column not found. Please check dataset column names.\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Target variable selected: {target_col}\")\n",
    "\n",
    "# Encode target variable\n",
    "y = df[target_col].replace({'Yes': 1, 'No': 0, 'Exited': 1, 'Active': 0}).fillna(0)\n",
    "\n",
    "# Drop target from feature set\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# ==========================\n",
    "# ðŸ§¹ 3. DATA CLEANING\n",
    "# ==========================\n",
    "# Handle categorical features\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "print(\"\\nâœ… Data cleaned successfully!\")\n",
    "print(\"Final shape after cleaning:\", X.shape)\n",
    "\n",
    "if X.shape[0] == 0:\n",
    "    raise ValueError(\"âŒ Dataset is empty after cleaning. Check preprocessing steps!\")\n",
    "\n",
    "# ==========================\n",
    "# ðŸ§ª 4. TRAIN/TEST SPLIT\n",
    "# ==========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“¦ Training set size:\", X_train.shape)\n",
    "print(\"ðŸ“¦ Testing set size:\", X_test.shape)\n",
    "\n",
    "# ==========================\n",
    "# ðŸ¤– 5. LOGISTIC REGRESSION\n",
    "# ==========================\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "log_pred = log_model.predict(X_test)\n",
    "log_acc = accuracy_score(y_test, log_pred)\n",
    "\n",
    "# ==========================\n",
    "# ðŸŒ² 6. RANDOM FOREST\n",
    "# ==========================\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# ==========================\n",
    "# ðŸ“ˆ 7. RESULTS\n",
    "# ==========================\n",
    "print(\"\\n=============================\")\n",
    "print(\"ðŸ“Š MODEL ACCURACY COMPARISON\")\n",
    "print(\"=============================\")\n",
    "print(f\"Logistic Regression Accuracy : {log_acc:.4f}\")\n",
    "print(f\"Random Forest Accuracy       : {rf_acc:.4f}\")\n",
    "\n",
    "# Optional detailed report\n",
    "print(\"\\nDetailed Classification Report (Random Forest):\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# ==========================\n",
    "# âœ… 8. CONCLUSION\n",
    "# ==========================\n",
    "if rf_acc > log_acc:\n",
    "    print(\"\\nâœ… Random Forest performs better than Logistic Regression.\")\n",
    "else:\n",
    "    print(\"\\nâœ… Logistic Regression performs better than Random Forest.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
